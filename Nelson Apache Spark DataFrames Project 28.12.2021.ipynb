{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55928771",
   "metadata": {},
   "source": [
    "## Apache Spark DataFrames Project_2021\n",
    "\n",
    "## Project Deliverable\n",
    "\n",
    "You will be required to submit:\n",
    "\n",
    "● A GitHub repository with your project written in Pyspark.\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "As a Data professional, you need to perform an analysis by answering questions about\n",
    "some stock market data on Safaricom from the years 2012-2017.\n",
    "You will need to perform the following:\n",
    "\n",
    "#### Data Importation and Exploration\n",
    "\n",
    "● Start a spark session and load the stock file while inferring the data types.\n",
    "\n",
    "● Determine the column names\n",
    "\n",
    "● Make observations about the schema.\n",
    "\n",
    "● Show the first 5 rows\n",
    "\n",
    "● Use the describe method to learn about the data frame\n",
    "\n",
    "#### Data Preparation\n",
    "Format all the data to 2 decimal places i.e. format_number()\n",
    "\n",
    "● Create a new data frame with a column called HV Ratio that is the ratio of the\n",
    "\n",
    "- High Price versus volume of stock traded for a day\n",
    "\n",
    "#### Data Analysis\n",
    "\n",
    "● What day had the Peak High in Price?\n",
    "\n",
    "● What is the mean of the Close column?\n",
    "\n",
    "● What is the max and min of the Volume column?\n",
    "\n",
    "● How many days was the Close lower than 60 dollars?\n",
    "\n",
    "● What percentage of the time was the High greater than 80 dollars?\n",
    "\n",
    "● What is the Pearson correlation between High and Volume?\n",
    "\n",
    "● What is the max High per year?\n",
    "\n",
    "● What is the average Close for each Calendar Month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701458ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\programdata\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.2)\n"
     ]
    }
   ],
   "source": [
    "##Pre-requisites\n",
    "# Installing pyspark\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1e439c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\programdata\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: py4j==0.10.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d4abdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "509b0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we run a local spark session\n",
    "# ---\n",
    "#\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4978b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "df_data_1 = sqlCtx.read.format(\"csv\").option(\"header\",\"true\").load(\"saf_stock.csv\")\n",
    "#Register the DataFrame as a SQL temporary view\n",
    "df_data_1.registerTempTable('saf_stock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5573a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#We now read our data set \n",
    "display(type(df_data_1))\n",
    "print(type(df_data_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd68f7f",
   "metadata": {},
   "source": [
    "#### Determine the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554fa27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581adb4",
   "metadata": {},
   "source": [
    "The stocks dataframe has the below columns\n",
    "\n",
    "['Date',]\n",
    "\n",
    "['Open', ]\n",
    "\n",
    "['High',]\n",
    "\n",
    "['Low', ]\n",
    "\n",
    "['Close',]\n",
    "\n",
    "['Volume',]\n",
    "\n",
    "['Adj Close]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e42d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+--------+---------+\n",
      "|     Date|     Open|     High|      Low|    Close|  Volume|Adj Close|\n",
      "+---------+---------+---------+---------+---------+--------+---------+\n",
      "| 1/3/2012|59.970001|61.060001|59.869999|60.330002|12668800|52.619235|\n",
      "| 1/4/2012|60.209999|60.349998|59.470001|59.709999| 9593300|52.078475|\n",
      "| 1/5/2012|59.349998|59.619999|58.369999|59.419998|12768200|51.825539|\n",
      "| 1/6/2012|59.419998|59.450001|58.869999|       59| 8069400| 51.45922|\n",
      "| 1/9/2012|59.029999|59.549999|58.919998|    59.18| 6679300|51.616215|\n",
      "|1/10/2012|    59.43|59.709999|    58.98|59.040001| 6907300|51.494109|\n",
      "|1/11/2012|59.060001|59.529999|59.040001|59.400002| 6365600|51.808098|\n",
      "|1/12/2012|59.790001|       60|59.400002|     59.5| 7236400|51.895316|\n",
      "|1/13/2012|    59.18|59.610001|59.009998|59.540001| 7729300|51.930204|\n",
      "|1/17/2012|59.869999|60.110001|    59.52|59.849998| 8500000|52.200581|\n",
      "|1/18/2012|59.790001|60.029999|59.650002|60.009998| 5911400|52.340131|\n",
      "|1/19/2012|    59.93|    60.73|    59.75|60.610001| 9234600|52.863447|\n",
      "|1/20/2012|    60.75|    61.25|60.669998|61.009998|10378800|53.212321|\n",
      "|1/23/2012|60.810001|    60.98|60.509998|    60.91| 7134100|53.125104|\n",
      "|1/24/2012|    60.75|       62|    60.75|61.389999| 7362800|53.543754|\n",
      "|1/25/2012|    61.18|61.610001|61.040001|61.470001| 5915800|53.613531|\n",
      "|1/26/2012|61.799999|    61.84|    60.77|60.970001| 7436200|53.177436|\n",
      "|1/27/2012|60.860001|61.119999|60.540001|60.709999| 6287300|52.950665|\n",
      "|1/30/2012|60.470001|    61.32|60.349998|61.299999| 7636900|53.465257|\n",
      "|1/31/2012|61.529999|    61.57|60.580002|61.360001| 9761500| 53.51759|\n",
      "+---------+---------+---------+---------+---------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlCtx.sql('SELECT * FROM saf_stock').show(20)# This is an SQL Query that returns the columns of the dataframe \n",
    "#with 20 results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02640ea7",
   "metadata": {},
   "source": [
    "### Make observations about the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3044e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e6107",
   "metadata": {},
   "source": [
    "- our dataframe has seven columns type of string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd7878",
   "metadata": {},
   "source": [
    "#### Show the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a5221da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+---------+---------+--------+---------+\n",
      "|    Date|     Open|     High|      Low|    Close|  Volume|Adj Close|\n",
      "+--------+---------+---------+---------+---------+--------+---------+\n",
      "|1/3/2012|59.970001|61.060001|59.869999|60.330002|12668800|52.619235|\n",
      "|1/4/2012|60.209999|60.349998|59.470001|59.709999| 9593300|52.078475|\n",
      "|1/5/2012|59.349998|59.619999|58.369999|59.419998|12768200|51.825539|\n",
      "|1/6/2012|59.419998|59.450001|58.869999|       59| 8069400| 51.45922|\n",
      "|1/9/2012|59.029999|59.549999|58.919998|    59.18| 6679300|51.616215|\n",
      "+--------+---------+---------+---------+---------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlCtx.sql('SELECT * FROM saf_stock').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a2b3a",
   "metadata": {},
   "source": [
    "#### Use the describe method to learn about the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cedf3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|     Date|             Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+---------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|     1258|             1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean|     null|72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|     null| 6.76809024470826|6.768186808159218|6.744075756255496| 6.75685916373299|  4519780.8431556|6.722609449996858|\n",
      "|    min|1/10/2012|        56.389999|        57.060001|        56.299999|        56.419998|         10010500|        50.363689|\n",
      "|    max| 9/9/2016|        90.800003|        90.970001|            89.25|        90.470001|          9994400|        84.914216|\n",
      "+-------+---------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Statistical summary of the dataframe\n",
    "sqlCtx.sql('SELECT * FROM saf_stock').describe().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198e560",
   "metadata": {},
   "source": [
    "Use the describe() method to calculate summary, statistics for the DataFrame and the show() method to display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2d90974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|     Date|             Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+---------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|     1258|             1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean|     null|72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|     null| 6.76809024470826|6.768186808159218|6.744075756255496| 6.75685916373299|  4519780.8431556|6.722609449996858|\n",
      "|    min|1/10/2012|        56.389999|        57.060001|        56.299999|        56.419998|         10010500|        50.363689|\n",
      "|    max| 9/9/2016|        90.800003|        90.970001|            89.25|        90.470001|          9994400|        84.914216|\n",
      "+-------+---------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#similarly it can be done as below.\n",
    "query = 'select * from saf_stock'\n",
    "sqlCtx.sql(query).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f20be",
   "metadata": {},
   "source": [
    "### 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48637e3e",
   "metadata": {},
   "source": [
    "- Format all the data to 2 decimal places i.e. format_number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7a6f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.types import DecimalType\n",
    "from pyspark.sql.functions import format_number,col\n",
    "cols = ['Open', 'High', 'Low', 'Close', 'Adj Close']\n",
    "for col in cols:\n",
    "  df_data_1 = df_data_1.withColumn(col, format_number(df_data_1[col].cast(\"float\"), 2))\n",
    "#conversion\n",
    "df_data_1 = df_data_1.withColumn('Volume', df_data_1.Volume.cast(DecimalType(18, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0280ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+-----+-----+-----------+---------+\n",
      "|     Date| Open| High|  Low|Close|     Volume|Adj Close|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+\n",
      "| 1/3/2012|59.97|61.06|59.87|60.33|12668800.00|    52.62|\n",
      "| 1/4/2012|60.21|60.35|59.47|59.71| 9593300.00|    52.08|\n",
      "| 1/5/2012|59.35|59.62|58.37|59.42|12768200.00|    51.83|\n",
      "| 1/6/2012|59.42|59.45|58.87|59.00| 8069400.00|    51.46|\n",
      "| 1/9/2012|59.03|59.55|58.92|59.18| 6679300.00|    51.62|\n",
      "|1/10/2012|59.43|59.71|58.98|59.04| 6907300.00|    51.49|\n",
      "|1/11/2012|59.06|59.53|59.04|59.40| 6365600.00|    51.81|\n",
      "|1/12/2012|59.79|60.00|59.40|59.50| 7236400.00|    51.90|\n",
      "|1/13/2012|59.18|59.61|59.01|59.54| 7729300.00|    51.93|\n",
      "|1/17/2012|59.87|60.11|59.52|59.85| 8500000.00|    52.20|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_1.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f28ea4",
   "metadata": {},
   "source": [
    "### Create a new data frame with a column called HV Ratio that is the ratio of the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1b457f",
   "metadata": {},
   "source": [
    "- HV Ratio that is the ratio of the High Price versus volume of stock traded for a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ea916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new column on our table\n",
    "df_data_2 = df_data_1.withColumn(\"HV_Ratio\", df_data_1.High/df_data_1.Volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "395babaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "|     Date| Open| High|  Low|Close|     Volume|Adj Close|            HV_Ratio|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "| 1/3/2012|59.97|61.06|59.87|60.33|12668800.00|    52.62|4.819714574387472E-6|\n",
      "| 1/4/2012|60.21|60.35|59.47|59.71| 9593300.00|    52.08|6.290848821573389...|\n",
      "| 1/5/2012|59.35|59.62|58.37|59.42|12768200.00|    51.83|4.669413073103491E-6|\n",
      "| 1/6/2012|59.42|59.45|58.87|59.00| 8069400.00|    51.46|7.367338339901356E-6|\n",
      "| 1/9/2012|59.03|59.55|58.92|59.18| 6679300.00|    51.62|8.915604928660188E-6|\n",
      "|1/10/2012|59.43|59.71|58.98|59.04| 6907300.00|    51.49|8.644477581688938E-6|\n",
      "|1/11/2012|59.06|59.53|59.04|59.40| 6365600.00|    51.81| 9.35182857861003E-6|\n",
      "|1/12/2012|59.79|60.00|59.40|59.50| 7236400.00|    51.90| 8.29141562102703E-6|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_2.show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c18740",
   "metadata": {},
   "source": [
    "- Lets convert the all the data set into two decimal places to maintain consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b51d34b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "|     Date| Open| High|  Low|Close|     Volume|Adj Close|            HV_Ratio|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "| 1/3/2012|59.97|61.06|59.87|60.33|12668800.00|    52.62|4.819714574387472E-6|\n",
      "| 1/4/2012|60.21|60.35|59.47|59.71| 9593300.00|    52.08|6.290848821573389...|\n",
      "| 1/5/2012|59.35|59.62|58.37|59.42|12768200.00|    51.83|4.669413073103491E-6|\n",
      "| 1/6/2012|59.42|59.45|58.87|59.00| 8069400.00|    51.46|7.367338339901356E-6|\n",
      "| 1/9/2012|59.03|59.55|58.92|59.18| 6679300.00|    51.62|8.915604928660188E-6|\n",
      "|1/10/2012|59.43|59.71|58.98|59.04| 6907300.00|    51.49|8.644477581688938E-6|\n",
      "|1/11/2012|59.06|59.53|59.04|59.40| 6365600.00|    51.81| 9.35182857861003E-6|\n",
      "|1/12/2012|59.79|60.00|59.40|59.50| 7236400.00|    51.90| 8.29141562102703E-6|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data_2.show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232cea4",
   "metadata": {},
   "source": [
    "### 4. Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8825a68",
   "metadata": {},
   "source": [
    "- Use the registerTempTable() or createOrReplaceTempView method to register the DataFrame df as a table named saf_stock_analysis.\n",
    "\n",
    "- Then we  run the SQLContext method tableNames to return the list of tables.\n",
    "\n",
    "- We Assign the resulting list to tables, and use the print function to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cff20cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saf_stock', 'saf_stock_analysis']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To register the DataFrame df as a table named saf_stock_analysis, run df.registerTempTable('saf_stock_analysis).\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "df_data_2.registerTempTable('saf_stock_analysis')\n",
    "tables =  sqlCtx.tableNames()#method name\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2de4c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "|     Date| Open| High|  Low|Close|     Volume|Adj Close|            HV_Ratio|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "| 1/3/2012|59.97|61.06|59.87|60.33|12668800.00|    52.62|4.819714574387472E-6|\n",
      "| 1/4/2012|60.21|60.35|59.47|59.71| 9593300.00|    52.08|6.290848821573389...|\n",
      "| 1/5/2012|59.35|59.62|58.37|59.42|12768200.00|    51.83|4.669413073103491E-6|\n",
      "| 1/6/2012|59.42|59.45|58.87|59.00| 8069400.00|    51.46|7.367338339901356E-6|\n",
      "| 1/9/2012|59.03|59.55|58.92|59.18| 6679300.00|    51.62|8.915604928660188E-6|\n",
      "|1/10/2012|59.43|59.71|58.98|59.04| 6907300.00|    51.49|8.644477581688938E-6|\n",
      "|1/11/2012|59.06|59.53|59.04|59.40| 6365600.00|    51.81| 9.35182857861003E-6|\n",
      "|1/12/2012|59.79|60.00|59.40|59.50| 7236400.00|    51.90| 8.29141562102703E-6|\n",
      "|1/13/2012|59.18|59.61|59.01|59.54| 7729300.00|    51.93|7.712211972623653E-6|\n",
      "|1/17/2012|59.87|60.11|59.52|59.85| 8500000.00|    52.20|7.071764705882352...|\n",
      "|1/18/2012|59.79|60.03|59.65|60.01| 5911400.00|    52.34|1.015495483303447...|\n",
      "|1/19/2012|59.93|60.73|59.75|60.61| 9234600.00|    52.86|6.576354146362592...|\n",
      "|1/20/2012|60.75|61.25|60.67|61.01|10378800.00|    53.21| 5.90145296180676E-6|\n",
      "|1/23/2012|60.81|60.98|60.51|60.91| 7134100.00|    53.13|8.547679455011844E-6|\n",
      "|1/24/2012|60.75|62.00|60.75|61.39| 7362800.00|    53.54|8.420709512685392E-6|\n",
      "|1/25/2012|61.18|61.61|61.04|61.47| 5915800.00|    53.61|1.041448324825044...|\n",
      "|1/26/2012|61.80|61.84|60.77|60.97| 7436200.00|    53.18|8.316075414862431E-6|\n",
      "|1/27/2012|60.86|61.12|60.54|60.71| 6287300.00|    52.95|9.721183974042911E-6|\n",
      "|1/30/2012|60.47|61.32|60.35|61.30| 7636900.00|    53.47|8.029436027707578E-6|\n",
      "|1/31/2012|61.53|61.57|60.58|61.36| 9761500.00|    53.52|6.307432259386365E-6|\n",
      "+---------+-----+-----+-----+-----+-----------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Write a SQL query that returns all column from the \n",
    "#saf_stock_analysis  and use the show() method to display the first 20 results\n",
    "sqlCtx.sql('select * from saf_stock_analysis').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07121524",
   "metadata": {},
   "source": [
    "### What day had the Peak High in Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd5e81cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|     Date|max(High)|\n",
      "+---------+---------+\n",
      "|1/13/2015|    90.97|\n",
      "+---------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create an sql query\n",
    "query_1 = 'select Date, max(High) from saf_stock_analysis group by 1 order by 2 desc'\n",
    "#Print the results to the console\n",
    "sqlCtx.sql(query_1).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc77cf",
   "metadata": {},
   "source": [
    "- Therefore 1/13/2015| had the highest price with 90.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df2b0b",
   "metadata": {},
   "source": [
    "#### What is the mean of the Close column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "550620f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Avg_Close|\n",
      "+---------+\n",
      "|    72.39|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create an sql query\n",
    "query_2 = 'select round(avg(Close),2) as Avg_Close from saf_stock_analysis group'\n",
    "#Print the results to the console\n",
    "sqlCtx.sql(query_2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188f34c",
   "metadata": {},
   "source": [
    "#### What is the max and min of the Volume column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb125f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "| Max_Volume|Min_Volume|\n",
      "+-----------+----------+\n",
      "|80898100.00|2094900.00|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create an sql query\n",
    "\n",
    "query_3 = 'select max(Volume) as Max_Volume, min(Volume) as Min_Volume from saf_stock_analysis group'\n",
    "#Print the results to the console\n",
    "sqlCtx.sql(query_3).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e15748",
   "metadata": {},
   "source": [
    "### How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57654720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(Date)|\n",
      "+-----------+\n",
      "|         81|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create an sql query\n",
    "\n",
    "query_4 = 'select count(Date) from saf_stock_analysis where Close < 60'\n",
    "#Print the results to the console\n",
    "sqlCtx.sql(query_4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e14260c",
   "metadata": {},
   "source": [
    "#### What percentage of the time was the High greater than 80 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4761623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|Over_80_Prop|\n",
      "+------------+\n",
      "|        8.43|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create an sql query\n",
    "query_5 = \"\"\"select round(Over_80/Total * 100,2) as Over_80_Prop from \n",
    "          (Select count(Date) as Total, sum(Case when High > 80 then 1 else 0 end) as Over_80 \n",
    "          From saf_stock_analysis)\"\"\"\n",
    "#Print the results to the console\n",
    "sqlCtx.sql(query_5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818347d6",
   "metadata": {},
   "source": [
    "#### What is the Pearson correlation between High and Volume?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "565692b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|High_Vol_Corr|\n",
      "+-------------+\n",
      "|        -0.34|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an sql query\n",
    "query_6 = 'select round(corr(High,Volume),2) as High_Vol_Corr from saf_stock_analysis'\n",
    "#Print the results to the console\n",
    "\n",
    "sqlCtx.sql(query_6).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce792fa",
   "metadata": {},
   "source": [
    "### What is the max High per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a2b6884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|Year|Year_High|\n",
      "+----+---------+\n",
      "|1/10|    78.72|\n",
      "|1/11|    68.79|\n",
      "|1/12|    90.31|\n",
      "|1/13|    90.97|\n",
      "|1/14|    88.52|\n",
      "|1/15|    87.78|\n",
      "|1/16|    87.46|\n",
      "|1/17|    76.82|\n",
      "|1/18|    69.20|\n",
      "|1/19|    62.80|\n",
      "|1/2/|    86.72|\n",
      "|1/20|    87.70|\n",
      "|1/21|    86.91|\n",
      "|1/22|    88.40|\n",
      "|1/23|    89.26|\n",
      "|1/24|    75.12|\n",
      "|1/25|    70.00|\n",
      "|1/26|    89.16|\n",
      "|1/27|    88.46|\n",
      "|1/28|    88.23|\n",
      "+----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Create an sql query\n",
    "query_7 = \"\"\"select substr(Date,1,4) as Year, max(High) as Year_High from saf_stock_analysis \n",
    "        group by 1 order by 1\"\"\"\n",
    "#Print the results to the console\n",
    "sqlCtx.sql(query_7).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d7038",
   "metadata": {},
   "source": [
    "#### What is the average Close for each Calendar Month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "556cd5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|Month|Monthly_Avg_Close|\n",
      "+-----+-----------------+\n",
      "|   /2|            72.39|\n",
      "|   0/|            71.65|\n",
      "|   1/|            72.29|\n",
      "|   2/|            72.69|\n",
      "|   20|            72.56|\n",
      "|   3/|            71.58|\n",
      "|   4/|            72.45|\n",
      "|   5/|             72.8|\n",
      "|   6/|             72.3|\n",
      "|   7/|             71.4|\n",
      "|   8/|            72.09|\n",
      "|   9/|             72.6|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an sql query\n",
    "query_8 = \"\"\"select substr(Date,5,2) as Month, round(avg(Close),2) as Monthly_Avg_Close \n",
    "            from saf_stock_analysis group by Month order by Month\"\"\"\n",
    "# Display the results\n",
    "sqlCtx.sql(query_8).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cba43d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
